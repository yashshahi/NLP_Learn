{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cb694a",
   "metadata": {},
   "source": [
    "## Stemming and its types - Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf72d2",
   "metadata": {},
   "source": [
    "stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the root of words known as lemma. stemming is important in Natural Language Understanding (NLU) and natural language processing (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdba088",
   "metadata": {},
   "outputs": [],
   "source": [
    "##for eg i have a classification problem\n",
    "##comments of product is a positive review or negative review\n",
    "##reviews--> eating ,eat ,eaten,---> this all shows one thing (eat)\n",
    "##simillary going ,gone,go represents (go) BASICALLY THE STEM IS SAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fef0175",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['eating',\"eat\", \"eaten\",\"writing\",\"write\",\"programing\",\"programs\",\"history\",\"finally \",\"finalize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "264193d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding word stem of each of the above words\n",
    "\n",
    "#1st technique porter stemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a54c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5b68e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eat----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "write----->write\n",
      "programing----->program\n",
      "programs----->program\n",
      "history----->histori\n",
      "finally ----->finally \n",
      "finalize----->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print (word+\"----->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4645f",
   "metadata": {},
   "source": [
    "major disadvanage is that the meaning of word History changed to histori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484404b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')\n",
    "#same changed the meaning of the word "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a817b",
   "metadata": {},
   "source": [
    "### RegexpStemmer class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495c9af",
   "metadata": {},
   "source": [
    "NLTK has regexpStemmer class with help of which we can easily implement Regular Expression Stemmer algorithms, it basically takes a singule regular expresson and removes prefix or suffix that matches the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47960763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a349d15",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RegexpStemmer.__init__() missing 1 required positional argument: 'regexp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reg_stemmer\u001b[38;5;241m=\u001b[39m\u001b[43mRegexpStemmer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: RegexpStemmer.__init__() missing 1 required positional argument: 'regexp'"
     ]
    }
   ],
   "source": [
    "reg_stemmer=RegexpStemmer()\n",
    "#keeping this error to remember what i did wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9341747",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
    "#where ever there is last words \"ing\",\"s\",e,\"able \" just try to remove that\n",
    "#only in the last ($ in the last means remove from end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d232654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8cc5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"ingeating\") #only in the last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755450bf",
   "metadata": {},
   "source": [
    "### RegexpStemmer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a816dba",
   "metadata": {},
   "source": [
    "NLTK has Regexpstemmer class which the help of which we can easily implement regular Expresson Stemmer algorithms it basically takes a single regular expression and removes a "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f42c37",
   "metadata": {},
   "source": [
    "### snowball stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b4299b",
   "metadata": {},
   "source": [
    "better than porter but porter have better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4d1c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dddc54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c6444bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eat------>eat\n",
      "eaten------>eaten\n",
      "writing------>write\n",
      "write------>write\n",
      "programing------>program\n",
      "programs------>program\n",
      "history------>histori\n",
      "finally ------>finally \n",
      "finalize------>final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"------>\"+snowballstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aea67e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5675303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem(\"fairly\"),snowballstemmer.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0501617c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ff492",
   "metadata": {},
   "source": [
    "Disadvantages are they dont always give correct response\n",
    "lemmatization solves all this particular problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
